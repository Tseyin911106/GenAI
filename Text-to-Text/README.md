## Text-to-Text (LLMs)

### Python sample codes
* `bailong-instruct-7b.py`
* `bloom-3b-zh.py`
* `breeze-7b-instruct.py`
* `gemma-1.1.py`
* `llama2.py`
* `mamba.py` # for -130M, -370M, -790M, -1B, -3B, -3B-slimpj
* `mistral-7b-instruct.py`
* `phi-2.py`
* `qwen1.5-7b-chat.py`
* `starling-lm-7b.py`
* `taide-lx-7b-chat.py`
* `taiwan-llm-7b.py`
* `vicuna-7b-v1.5.py`

---
### local-LLM Server & Client
* `python llm_server.py` (on your PC's GPU)
* `python post_text.py`  (on your PC's CPU)

---
### Colab's LLM Server & Client
* [pyngrok-LLM server](https://github.com/rkuo2000/GenAI/blob/main/Text-to-Text/pyngrok_LLM_Server.ipynb) (on Colab T4)<br>
![](https://github.com/rkuo2000/GenAI/blob/main/assets/pyngrok_LLM_Server.png?raw=true)
* [post-text client](https://github.com/rkuo2000/GenAI/blob/main/Text-to-Text/post_text.py) (on your PC)<br>
![](https://github.com/rkuo2000/GenAI/blob/main/assets/pyngrok_post_text.png?raw=true)

