{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDHLVChQFnM3"
   },
   "source": [
    "# LLM Whisper HTTP Server\n",
    "## with pyNgrok tunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15FGYusaCg2s",
    "outputId": "95305316-c698-43f8-811f-f13523980f6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-q09ojz8o\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-q09ojz8o\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numba in /home/rkuo/miniconda3/lib/python3.12/site-packages (from openai-whisper==20231117) (0.59.0)\n",
      "Requirement already satisfied: numpy in /home/rkuo/miniconda3/lib/python3.12/site-packages (from openai-whisper==20231117) (1.26.4)\n",
      "Requirement already satisfied: torch in /home/rkuo/miniconda3/lib/python3.12/site-packages (from openai-whisper==20231117) (2.2.1)\n",
      "Requirement already satisfied: tqdm in /home/rkuo/miniconda3/lib/python3.12/site-packages (from openai-whisper==20231117) (4.65.0)\n",
      "Requirement already satisfied: more-itertools in /home/rkuo/miniconda3/lib/python3.12/site-packages (from openai-whisper==20231117) (10.2.0)\n",
      "Requirement already satisfied: tiktoken in /home/rkuo/miniconda3/lib/python3.12/site-packages (from openai-whisper==20231117) (0.6.0)\n",
      "Requirement already satisfied: triton<3,>=2.0.0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from openai-whisper==20231117) (2.2.0)\n",
      "Requirement already satisfied: filelock in /home/rkuo/miniconda3/lib/python3.12/site-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from numba->openai-whisper==20231117) (0.42.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (1.12)\n",
      "Requirement already satisfied: networkx in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.4.99)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
      "Requirement already satisfied: fastapi in /home/rkuo/miniconda3/lib/python3.12/site-packages (0.110.0)\n",
      "Requirement already satisfied: uvicorn in /home/rkuo/miniconda3/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from fastapi) (2.6.4)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from fastapi) (0.36.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from fastapi) (4.10.0)\n",
      "Requirement already satisfied: click>=7.0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from uvicorn) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from uvicorn) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.16.3)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from starlette<0.37.0,>=0.36.3->fastapi) (4.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi) (2.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi) (1.3.1)\n",
      "Requirement already satisfied: pyngrok in /home/rkuo/miniconda3/lib/python3.12/site-packages (7.1.5)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from pyngrok) (6.0.1)\n",
      "Requirement already satisfied: accelerate in /home/rkuo/miniconda3/lib/python3.12/site-packages (0.29.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /home/rkuo/miniconda3/lib/python3.12/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/rkuo/miniconda3/lib/python3.12/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/rkuo/miniconda3/lib/python3.12/site-packages (from accelerate) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.99)\n",
      "Requirement already satisfied: requests in /home/rkuo/miniconda3/lib/python3.12/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/rkuo/miniconda3/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: einops in /home/rkuo/miniconda3/lib/python3.12/site-packages (0.7.0)\n",
      "Requirement already satisfied: nest-asyncio in /home/rkuo/miniconda3/lib/python3.12/site-packages (1.6.0)\n",
      "Requirement already satisfied: python-multipart in /home/rkuo/miniconda3/lib/python3.12/site-packages (0.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/openai/whisper.git\n",
    "!pip install fastapi uvicorn\n",
    "!pip install pyngrok\n",
    "!pip install accelerate\n",
    "!pip install einops\n",
    "!pip install nest-asyncio\n",
    "!pip install python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8lrTN01hmTH2"
   },
   "outputs": [],
   "source": [
    "import whisper\n",
    "ASR = whisper.load_model(\"base\").to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIfBBrPmGkcb"
   },
   "source": [
    "## LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RSaQOUKpGZuZ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM , AutoTokenizer\n",
    "\n",
    "### https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard\n",
    "model_name = \"Q-bert/Mamba-130M\"\n",
    "#model_name = \"Q-bert/Mamba-370M\"\n",
    "#model_name = \"Q-bert/Mamba-790M\"\n",
    "#model_name = \"Q-bert/Mamba-1B\"\n",
    "#model_name = \"Q-bert/Mamba-3B\"\n",
    "#model_name = \"Q-bert/Mamba-3B-slimpj\"\n",
    "#model_name = \"ckip-joint/bloom-3b-zh\" # zh\n",
    "#model_name = \"google/gemma-1.1-7b-it\"\n",
    "#model_name = \"microsoft/phi-2\"\n",
    "#model_name = \"microsoft/Orca-2-7b\"\n",
    "#model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "#model_name = \"openlm-research/open_llama_3b_v2\"\n",
    "#model_name = \"openlm-research/open_llama_7b_v2\"\n",
    "#model_name = \"meta-llama/Llama-2-7b-hf\"\n",
    "#model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "#model_name = \"lmsys/vicuna-7b-v1.5\"\n",
    "#model_name = \"lmsys/vicuna-7b-v1.5-16k\"\n",
    "#model_name = \"Nexusflow/Starling-LM-7B-beta\"\n",
    "\n",
    "#model_name = \"Qwen/Qwen1.5-7B-Chat\" # 通义千问\n",
    "#model_name = \"01-ai/Yi-6B-Chat\" # 零一万物\n",
    "#model_name = \"yentinglin/Taiwan-LLM-7B-v2.0.1-chat\" # 台大\n",
    "#model_name = \"MediaTek-Research/Breeze-7B-Instruct-v0.1\" # 達哥\n",
    "#model_name = \"INX-TEXT/Bailong-instruct-7B\" # zh 白龍\n",
    "#model_name = \"taide/TAIDE-LX-7B-Chat\" # TAIDE\n",
    "\n",
    "\n",
    "LLM = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, torch_dtype=\"auto\", device_map=\"cuda\") # for Mamba\n",
    "#LLM = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, torch_dtype=torch.bfloat16, device_map=\"cuda\") # for the rest models\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOczh9szG2Ik"
   },
   "source": [
    "## HTTP Server with Ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "code",
    "id": "vPc_bodwBQmM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "import threading\n",
    "\n",
    "from pyngrok import ngrok, conf\n",
    "\n",
    "\n",
    "## set ngrok authtoken\n",
    "print(\"Enter your authtoken, which can be copied from https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
    "conf.get_default().auth_token = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eFus3mCLnK0S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * ngrok tunnel \"https://ecf1-2407-4d00-8d00-00-f8.ngrok-free.app\" -> \"http://127.0.0.1:5000/\"\n"
     ]
    }
   ],
   "source": [
    "# Open a ngrok tunnel to the HTTP server\n",
    "public_url = ngrok.connect(5000).public_url\n",
    "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}/\\\"\".format(public_url, 5000))\n",
    "\n",
    "# ... Update inbound traffic via APIs to use the public-facing ngrok URL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "094TI5u1R0xF"
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGupeygymn1G"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [22523]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:5000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gTTS.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rkuo/miniconda3/lib/python3.12/site-packages/whisper/transcribe.py:124: UserWarning: Performing inference on CPU when CUDA is available\n",
      "  warnings.warn(\"Performing inference on CPU when CUDA is available\")\n",
      "/home/rkuo/miniconda3/lib/python3.12/site-packages/whisper/transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whisper:  Hello, how are you?\n",
      "LLM:  Hello, how are you?\n",
      "\n",
      "I’m so glad you’re here. I’ve been waiting for you for a long time, and it’s been a pleasure to meet you. We’d like to talk a little bit about what we do and how we can help you, so let me start by saying that we are a small team, but we have a lot of work to do. So, we want to make sure that you get the most out of your time with us. And we’ll be happy to answer any questions you may have. If you need anything, just let us know.\n",
      "\n",
      "INFO:     2407:4d00:8d00::f8:0 - \"POST /audio HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI, File, UploadFile\n",
    "from fastapi.responses import Response\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "import json\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return Response(\"Hello World!\")\n",
    "\n",
    "@app.post(\"/audio\")\n",
    "def post_audio(audio: UploadFile = File(...)):\n",
    "    print(audio.filename)\n",
    "    fname = 'tmp_'+audio.filename\n",
    "    with open(fname, 'wb') as f:\n",
    "        content = audio.file.read()\n",
    "        f.write(content)\n",
    "\n",
    "    # Whisper transcribe\n",
    "    result = ASR.transcribe(fname)\n",
    "    print(\"ASR: \"+result[\"text\"])\n",
    "\n",
    "    prompt = result[\"text\"]\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output = LLM.generate(input_ids, max_length=128, num_beams=5, no_repeat_ngram_size=2)\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    print(\"LLM: \"+generated_text)\n",
    "    return Response(generated_text)\n",
    "\n",
    "# start new thread\n",
    "threading.Thread(uvicorn.run(app, host=\"127.0.0.1\", port=5000, log_level=\"info\")).start()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
